{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8f18b23",
   "metadata": {
    "papermill": {
     "duration": 0.006395,
     "end_time": "2022-04-18T00:08:55.010149",
     "exception": false,
     "start_time": "2022-04-18T00:08:55.003754",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Get started with SageMaker Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddd83f9",
   "metadata": {
    "papermill": {
     "duration": 0.006395,
     "end_time": "2022-04-18T00:08:55.010149",
     "exception": false,
     "start_time": "2022-04-18T00:08:55.003754",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "## Runtime\n",
    "\n",
    "This notebook takes approximately 5 minutes to run.\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Prepare resources](#Prepare-resources)\n",
    "1. [Download data](#Download-data)\n",
    "1. [Prepare Processing script](#Prepare-Processing-script)\n",
    "1. [Run Processing job](#Run-Processing-job)\n",
    "1. [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf7028a",
   "metadata": {
    "papermill": {
     "duration": 0.006333,
     "end_time": "2022-04-18T00:08:55.022942",
     "exception": false,
     "start_time": "2022-04-18T00:08:55.016609",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Prepare resources\n",
    "\n",
    "First, let’s create an SKLearnProcessor object, passing the scikit-learn version we want to use, as well as our managed infrastructure requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "862f8d1f",
   "metadata": {
    "papermill": {
     "duration": 1.028712,
     "end_time": "2022-04-18T00:08:56.058050",
     "exception": false,
     "start_time": "2022-04-18T00:08:55.029338",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "region = sagemaker.Session().boto_region_name\n",
    "role = get_execution_role()\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"1.2-1\",\n",
    "    role=role,\n",
    "    instance_type=\"ml.t3.medium\",\n",
    "    instance_count=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35ea4ea",
   "metadata": {
    "papermill": {
     "duration": 0.006588,
     "end_time": "2022-04-18T00:08:56.071404",
     "exception": false,
     "start_time": "2022-04-18T00:08:56.064816",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Download data\n",
    "\n",
    "Read in the raw data from a public S3 bucket. This example uses the [Census-Income (KDD) Dataset](https://archive.ics.uci.edu/ml/datasets/Census-Income+%28KDD%29) from the UCI Machine Learning Repository.\n",
    "\n",
    "> Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7339f25f-d329-4665-8608-60ab2e7d94ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6eaf6050",
   "metadata": {
    "papermill": {
     "duration": 4.738175,
     "end_time": "2022-04-18T00:09:00.816126",
     "exception": false,
     "start_time": "2022-04-18T00:08:56.077951",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>lastname</th>\n",
       "      <th>phonenumber</th>\n",
       "      <th>age</th>\n",
       "      <th>delete_at</th>\n",
       "      <th>update_at</th>\n",
       "      <th>messages_count</th>\n",
       "      <th>domain</th>\n",
       "      <th>country_Afghanistan</th>\n",
       "      <th>...</th>\n",
       "      <th>country_Togo</th>\n",
       "      <th>country_Turks and Caicos Islands</th>\n",
       "      <th>country_Ukraine</th>\n",
       "      <th>country_Vanuatu</th>\n",
       "      <th>country_Venezuela</th>\n",
       "      <th>is_male</th>\n",
       "      <th>age_group</th>\n",
       "      <th>create_at_day</th>\n",
       "      <th>create_at_month</th>\n",
       "      <th>create_at_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Megan</td>\n",
       "      <td>Merritt</td>\n",
       "      <td>+1-594-583-4845</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>yahoo.com</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30-50</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>John</td>\n",
       "      <td>Mason</td>\n",
       "      <td>001-445-250-1527</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>yahoo.com</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50+</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Andrea</td>\n",
       "      <td>Mcmillan</td>\n",
       "      <td>001-968-598-1591x372</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63</td>\n",
       "      <td>yahoo.com</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30-50</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Morgan</td>\n",
       "      <td>Dougherty</td>\n",
       "      <td>(253)248-0847x34345</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30-50</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Carl</td>\n",
       "      <td>Green</td>\n",
       "      <td>+1-914-358-0492x6972</td>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77</td>\n",
       "      <td>outlook.com</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30-50</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    name   lastname           phonenumber  age  delete_at  update_at  \\\n",
       "0   1   Megan    Merritt       +1-594-583-4845   40        NaN        NaN   \n",
       "1   2    John      Mason      001-445-250-1527   95        NaN        NaN   \n",
       "2   3  Andrea   Mcmillan  001-968-598-1591x372   31        NaN        NaN   \n",
       "3   4  Morgan  Dougherty   (253)248-0847x34345   44        NaN        NaN   \n",
       "4   5    Carl      Green  +1-914-358-0492x6972   47        NaN        NaN   \n",
       "\n",
       "   messages_count       domain  country_Afghanistan  ...  country_Togo  \\\n",
       "0              13    yahoo.com                    0  ...             0   \n",
       "1              17    yahoo.com                    0  ...             0   \n",
       "2              63    yahoo.com                    0  ...             0   \n",
       "3              91    gmail.com                    0  ...             0   \n",
       "4              77  outlook.com                    0  ...             0   \n",
       "\n",
       "   country_Turks and Caicos Islands  country_Ukraine  country_Vanuatu  \\\n",
       "0                                 0                0                0   \n",
       "1                                 0                0                0   \n",
       "2                                 0                0                0   \n",
       "3                                 0                0                0   \n",
       "4                                 0                0                0   \n",
       "\n",
       "   country_Venezuela  is_male  age_group  create_at_day  create_at_month  \\\n",
       "0                  0        1      30-50             21                7   \n",
       "1                  0        1        50+             21                7   \n",
       "2                  0        0      30-50             21                7   \n",
       "3                  0        1      30-50             21                7   \n",
       "4                  0        0      30-50             21                7   \n",
       "\n",
       "   create_at_year  \n",
       "0            2025  \n",
       "1            2025  \n",
       "2            2025  \n",
       "3            2025  \n",
       "4            2025  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3.download_file(\n",
    "    \"fady-my-bucket\",\n",
    "    \"sagemaker/input/data.csv\",\n",
    "    \"input_data.csv\",\n",
    ")\n",
    "df = pd.read_csv(\"input_data.csv\")\n",
    "df.to_csv(\"dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240ac1a3",
   "metadata": {
    "papermill": {
     "duration": 0.007158,
     "end_time": "2022-04-18T00:09:00.830803",
     "exception": false,
     "start_time": "2022-04-18T00:09:00.823645",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Prepare Processing script\n",
    "\n",
    "Write the Python script that will be run by SageMaker Processing. This script reads the single data file from S3; splits the rows into train, test, and validation sets; and then writes the three output files to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b8e90c",
   "metadata": {
    "papermill": {
     "duration": 0.013691,
     "end_time": "2022-04-18T00:09:00.851669",
     "exception": false,
     "start_time": "2022-04-18T00:09:00.837978",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocessing_fady.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocessing_fady.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Performs data preprocessing steps on the input DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing raw data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The preprocessed DataFrame.\n",
    "    \"\"\"\n",
    "    print(\"Starting data preprocessing...\")\n",
    "    df = pd.read_csv(\"/opt/ml/processing/input/data.csv\")\n",
    "\n",
    "    # --- Step 1: Extract domain name from email and create 'domain' column ---\n",
    "    if 'email' in df.columns:\n",
    "        df['domain'] = df['email'].apply(lambda x: x.split('@')[1] if pd.notna(x) and '@' in x else np.nan)\n",
    "        df = df.drop(columns=['email'])\n",
    "        print(\"Extracted domain from email and removed original email column.\")\n",
    "    else:\n",
    "        print(\"Email column not found. Skipping domain extraction.\")\n",
    "\n",
    "    # --- Step 2: Apply one-hot encoding to 'country' column ---\n",
    "    if 'country' in df.columns:\n",
    "        # Handle potential non-string values or NaNs before one-hot encoding\n",
    "        df['country'] = df['country'].astype(str).replace('nan', 'Unknown')\n",
    "        df = pd.get_dummies(df, columns=['country'], prefix='country', drop_first=False)\n",
    "        print(\"Applied one-hot encoding to 'country' column and removed original country column.\")\n",
    "    else:\n",
    "        print(\"Country column not found. Skipping one-hot encoding.\")\n",
    "\n",
    "    # --- Step 3: Create 'is_male' based on 'gender' and remove original 'gender' ---\n",
    "    if 'gender' in df.columns:\n",
    "        # Assuming 'Male' indicates male, and other values (e.g., 'Female', NaN) are not male\n",
    "        df['is_male'] = df['gender'].apply(lambda x: 1 if str(x).lower() == 'male' else 0)\n",
    "        df = df.drop(columns=['gender'])\n",
    "        print(\"Created 'is_male' column and removed original gender column.\")\n",
    "    else:\n",
    "        print(\"Gender column not found. Skipping 'is_male' creation.\")\n",
    "\n",
    "    # --- Step 4: Fill age nulls with the mean average ---\n",
    "    if 'age' in df.columns:\n",
    "        if df['age'].isnull().any():\n",
    "            mean_age = df['age'].mean()\n",
    "            df['age'].fillna(mean_age, inplace=True)\n",
    "            print(f\"Filled age nulls with mean average: {mean_age:.2f}\")\n",
    "        else:\n",
    "            print(\"No nulls found in 'age' column.\")\n",
    "    else:\n",
    "        print(\"Age column not found. Skipping age null filling.\")\n",
    "\n",
    "    # --- Step 5: Convert 'age' into 4 different groups ---\n",
    "    if 'age' in df.columns:\n",
    "        # Define age bins and labels\n",
    "        bins = [0, 18, 30, 50, np.inf]\n",
    "        labels = ['0-18', '18-30', '30-50', '50+']\n",
    "        # Ensure age column is numeric before cutting\n",
    "        df['age'] = pd.to_numeric(df['age'], errors='coerce')\n",
    "        df['age_group'] = pd.cut(df['age'], bins=bins, labels=labels, right=False, include_lowest=True)\n",
    "        # Convert age_group to string or integer if needed for downstream tasks,\n",
    "        # or keep as categorical if preferred. For simplicity, we'll keep it as categorical\n",
    "        # or convert to string if saving to CSV/Parquet.\n",
    "        # df['age_group'] = df['age_group'].astype(str) # Uncomment if you want string representation\n",
    "        df = df.drop(columns=['age']) # Remove original age column\n",
    "        print(\"Converted 'age' into 4 different groups and removed original age column.\")\n",
    "    else:\n",
    "        print(\"Age column not found. Skipping age grouping.\")\n",
    "\n",
    "    # --- Step 6: Convert 'created_at' into separate columns ---\n",
    "    if 'created_at' in df.columns:\n",
    "        df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')\n",
    "        df['created_at_day'] = df['created_at'].dt.day\n",
    "        df['created_at_month'] = df['created_at'].dt.month\n",
    "        df['created_at_year'] = df['created_at'].dt.year\n",
    "        df = df.drop(columns=['created_at'])\n",
    "        print(\"Converted 'created_at' into day, month, year columns and removed original 'created_at'.\")\n",
    "    else:\n",
    "        print(\"Created_at column not found. Skipping date conversion.\")\n",
    "\n",
    "    print(\"Data preprocessing complete.\")\n",
    "    return df\n",
    "\n",
    "# --- Data Loading, Preprocessing, and Saving (for Jupyter Notebook execution) ---\n",
    "\n",
    "# Define input and output paths for local execution within Jupyter\n",
    "# In a SageMaker Processing Job, these paths would be automatically set by SageMaker\n",
    "input_data_path = \"/opt/ml/processing/input/data.csv\" # Assuming input CSV is in the same directory as the notebook\n",
    "output_data_path = \"/opt/ml/processing/output/preprocessed_data.csv\" # Output CSV will be saved here\n",
    "\n",
    "# Create dummy data for local testing if the input file doesn't exist\n",
    "if not os.path.exists(input_data_path):\n",
    "    print(\"Input file not found, creating dummy DataFrame for local testing.\")\n",
    "    data = {\n",
    "        'email': ['user1@example.com', 'user2@domain.net', 'user3@sub.org', 'invalid-email', np.nan],\n",
    "        'country': ['USA', 'Canada', 'USA', 'Mexico', np.nan],\n",
    "        'gender': ['Male', 'Female', 'Male', 'Other', np.nan],\n",
    "        'age': [25, 35, np.nan, 15, 55],\n",
    "        'created_at': ['2023-01-15', '2022-11-01', '2023-05-20', '2024-02-29', np.nan],\n",
    "        'value': [100, 200, 150, 300, 250]\n",
    "    }\n",
    "    df_raw = pd.DataFrame(data)\n",
    "    df_raw.to_csv(input_data_path, index=False)\n",
    "    print(f\"Dummy data saved to {input_data_path}\")\n",
    "\n",
    "# Load the data\n",
    "try:\n",
    "    df_raw = pd.read_csv(input_data_path)\n",
    "    print(f\"Successfully loaded data from {input_data_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data from {input_data_path}: {e}\")\n",
    "    # In a Jupyter notebook, you might want to raise the error or handle it differently\n",
    "    # For a script that might be run in a non-interactive way, exiting is fine.\n",
    "    # raise e # Uncomment to raise the exception in Jupyter\n",
    "    exit(1)\n",
    "\n",
    "# Preprocess the data\n",
    "df_processed = preprocess_data(df_raw.copy())\n",
    "\n",
    "# Save the preprocessed data\n",
    "try:\n",
    "    df_processed.to_csv(output_data_path, index=False)\n",
    "    print(f\"Preprocessed data saved to {output_data_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving preprocessed data to {output_data_path}: {e}\")\n",
    "    # raise e # Uncomment to raise the exception in Jupyter\n",
    "    exit(1)\n",
    "\n",
    "print(\"Script finished.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bab3ff2",
   "metadata": {
    "papermill": {
     "duration": 0.007373,
     "end_time": "2022-04-18T00:09:00.866414",
     "exception": false,
     "start_time": "2022-04-18T00:09:00.859041",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Run Processing job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68190117",
   "metadata": {
    "papermill": {
     "duration": 0.007318,
     "end_time": "2022-04-18T00:09:00.881109",
     "exception": false,
     "start_time": "2022-04-18T00:09:00.873791",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "Run the Processing job, specifying the script name, input file, and output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "450368db",
   "metadata": {
    "papermill": {
     "duration": 283.713812,
     "end_time": "2022-04-18T00:13:44.602351",
     "exception": false,
     "start_time": "2022-04-18T00:09:00.888539",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "# Run the processing job with the specified job name\n",
    "# Assuming sklearn_processor is already defined as in the previous example\n",
    "sklearn_processor.run(\n",
    "    code=\"preprocessing_fady.py\",  # Path to your preprocessing script\n",
    "    job_name=\"sagemaker-fady-1\",   # Your desired job name\n",
    "    # arguments=[],                 # No arguments needed for the current script\n",
    "    inputs=[\n",
    "        # This assumes your 'dataset.csv' is uploaded to an S3 location\n",
    "        # and SageMaker will mount it to /opt/ml/processing/input/dataset.csv\n",
    "        # The script expects 'input.csv', so you might need to rename or adjust.\n",
    "        # If dataset.csv is the only file, it will be mounted as /opt/ml/processing/input/dataset.csv\n",
    "        # If your script expects 'input.csv', you might need to adjust the source or script.\n",
    "        # For consistency with the script, consider naming your S3 input file 'input.csv'\n",
    "        # and setting the source to its S3 URI.\n",
    "        ProcessingInput(\n",
    "            source=\"s3://fady-my-bucket/sagemaker/input/data.csv\", # Example S3 path\n",
    "            destination=\"/opt/ml/processing/input\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        # The preprocessing_script currently outputs 'preprocessed_data.csv'\n",
    "        # to /opt/ml/processing/output/.\n",
    "        # If you want separate train/validation/test outputs, your script\n",
    "        # would need to be modified to create those files.\n",
    "        # For now, it will save preprocessed_data.csv to the base output path.\n",
    "        ProcessingOutput(\n",
    "            source=\"/opt/ml/processing/output\", # This is where your script writes 'preprocessed_data.csv'\n",
    "            destination=\"s3://fady-my-bucket/sagemaker/output/\" # S3 path for all output\n",
    "        )\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135c2776",
   "metadata": {
    "papermill": {
     "duration": 0.007543,
     "end_time": "2022-04-18T00:13:44.617780",
     "exception": false,
     "start_time": "2022-04-18T00:13:44.610237",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "Get the Processing job logs and retrieve the job name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2355fc7-940c-4dcf-9726-f01287e8c3a6",
   "metadata": {},
   "source": [
    "You Get an ERROR, what is this error? where I can see the logs?\n",
    "\n",
    "> Please check in cloudwatch for logs and fix the issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f3e9edf",
   "metadata": {
    "papermill": {
     "duration": 0.013467,
     "end_time": "2022-04-18T00:13:44.638753",
     "exception": false,
     "start_time": "2022-04-18T00:13:44.625286",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................\u001b[34mInput file not found, creating dummy DataFrame for local testing.\u001b[0m\n",
      "\u001b[34mDummy data saved to input.csv\u001b[0m\n",
      "\u001b[34mSuccessfully loaded data from input.csv\u001b[0m\n",
      "\u001b[34mStarting data preprocessing...\u001b[0m\n",
      "\u001b[34mExtracted domain from email and removed original email column.\u001b[0m\n",
      "\u001b[34mApplied one-hot encoding to 'country' column and removed original country column.\u001b[0m\n",
      "\u001b[34mCreated 'is_male' column and removed original gender column.\u001b[0m\n",
      "\u001b[34mFilled age nulls with mean average: 32.50\u001b[0m\n",
      "\u001b[34mConverted 'age' into 4 different groups and removed original age column.\u001b[0m\n",
      "\u001b[34mConverted 'created_at' into day, month, year columns and removed original 'created_at'.\u001b[0m\n",
      "\u001b[34mData preprocessing complete.\u001b[0m\n",
      "\u001b[34mPreprocessed data saved to preprocessed_data.csv\u001b[0m\n",
      "\u001b[34mScript finished.\u001b[0m\n",
      "\u001b[35mInput file not found, creating dummy DataFrame for local testing.\u001b[0m\n",
      "\u001b[35mDummy data saved to input.csv\u001b[0m\n",
      "\u001b[35mSuccessfully loaded data from input.csv\u001b[0m\n",
      "\u001b[35mStarting data preprocessing...\u001b[0m\n",
      "\u001b[35mExtracted domain from email and removed original email column.\u001b[0m\n",
      "\u001b[35mApplied one-hot encoding to 'country' column and removed original country column.\u001b[0m\n",
      "\u001b[35mCreated 'is_male' column and removed original gender column.\u001b[0m\n",
      "\u001b[35mFilled age nulls with mean average: 32.50\u001b[0m\n",
      "\u001b[35mConverted 'age' into 4 different groups and removed original age column.\u001b[0m\n",
      "\u001b[35mConverted 'created_at' into day, month, year columns and removed original 'created_at'.\u001b[0m\n",
      "\u001b[35mData preprocessing complete.\u001b[0m\n",
      "\u001b[35mPreprocessed data saved to preprocessed_data.csv\u001b[0m\n",
      "\u001b[35mScript finished.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name sagemaker-fady-1\n"
     ]
    }
   ],
   "source": [
    "output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386f656a",
   "metadata": {
    "papermill": {
     "duration": 0.007802,
     "end_time": "2022-04-18T00:13:44.654395",
     "exception": false,
     "start_time": "2022-04-18T00:13:44.646593",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "Confirm that the output dataset files were written to S3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd191e62",
   "metadata": {
    "papermill": {
     "duration": 0.008184,
     "end_time": "2022-04-18T00:13:45.060991",
     "exception": false,
     "start_time": "2022-04-18T00:13:45.052807",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we read a dataset from S3 and processed it into train, test, and validation sets using a SageMaker Processing job. You can extend this example for preprocessing your own datasets in preparation for machine learning or other applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 291.085709,
   "end_time": "2022-04-18T00:13:45.485219",
   "environment_variables": {},
   "exception": null,
   "input_path": "basic_sagemaker_processing.ipynb",
   "output_path": "/opt/ml/processing/output/basic_sagemaker_processing-2022-04-18-00-04-13.ipynb",
   "parameters": {
    "kms_key": "arn:aws:kms:us-west-2:000000000000:1234abcd-12ab-34cd-56ef-1234567890ab"
   },
   "start_time": "2022-04-18T00:08:54.399510",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
